# Week of September 25

This assignment is due EOD on October 2, 2025.
Requirements: Task 1 AND Task 2 AND (Task 3 OR Task 4).

## Submission

As you are working, you can [commit and push](https://docs.github.com/en/get-started/using-git/about-git) to your fork. 
To submit the assignment, you will [create a Pull Request](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request-from-a-fork) (PR) with the main [collaborative](https://github.com/ml-feedback-sys/collaborative-f25) repository.
Please title the PR "09-25 Submission - `netID`" and include a description of the work that you did.

Make sure you are keeping your fork [up to date](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/working-with-forks/syncing-a-fork).
Any files that you submit should be in your folder in the collaborative repository (`submission/netID`).

## Task 1: Implement HMM and discrete filtering

In this assignment, we will consider filtering and prediction for discrete hidden Markov models.

Pick some model of transitions $P$ and observations $B$. 
You can find some example online, add an observation model to the Markov transitions from the 9-04 assignment, or select something arbitrarily.

Implement the model in code.
You may want to use an object to keep track of the internal state. 
You may generate transitions and observations by sampling with `np.random.choice`.

Next, implement the discrete filtering algorithm discussed in lecture.
You may want to use an object to keep track of the posterior state distribution.
You should also compute the posterior observation distribution of $y_{t+k|t}$.

Starting from a random initial state, generate observations from the HMM and pass them to the discrete filter.
Plot the posterior state and observation distribution (of $y_{t+1|t}$) over time.
Does it appear to converge?
How does it compare with the empirial frequencies of observations?
Provide these plots along with answers to these questions in your PR.

## Task 2: Train an autoregressive model

Now, rather than using a filtering algorithm, we will learn a model from data.
First, collect several sequences of obervations from the HMM. 
Split this data into test and train data. You may want to split the data both by sequence and by time step.
Set up a multiclass classification problem (you may use e.g. the `sklearn` package) to predict the next observation $\hat y_t$ based on the previous $L$ outputs $y_{t-1},\dots,y_{t-L}$.
Investigate the performance of this model on test data.
Compare it against the performance of the optimal approach: predicting $\max_y P(y_{t|t-1}=y)$ where the distribution is computed by the filter above.
What happens as you increase or decrease $L$?
Include plots in your PR.

## (pick one) Task 3: Baum-Welch algorithm

Unlike the AR model, the filtering algorithm relies on knowing the parameters of the underying HMM data generation process.
You can derive a data-driven filter by fitting $\hat P$ and $\hat B$ from training data. 
Then you will evaluate its performance on testing data.
To fit $\hat P$ and $\hat B$, try the following procedure, which can be understood as an alternating minimization in the spirit of the EM algorithm.
It is known as the Baum-Welch algorithm.
Initialize your model with some random $\hat P_0$ and $\hat B_0$ (you may want to try multiple initializations). 
Then:
1. Run the Viterbi algorithm (https://en.wikipedia.org/wiki/Viterbi_algorithm) with the estimated parameters to find the Maximum A Priori sequence of states 
2. Use the estimated states to fit new parameters (by counting the empirical frequencies)
3. Repeat to convergence

Compare the performance of Baum-Welch on test data to the AR model.

## (pick one) Task 4: Make predictions from streaming data

Select one of the supervised learning settings from any of the past assignments (Kauirec, dynamical systems, autoregressive models). 
We will now consider this problem from an *online learning* perspective.
Modify the logic of the data aquisition and training process to be online: data arrives sequentially, and you must make predictions at every step before the true label is revealed.
Your model will need to be instantiated with minimal data and updated incrementally.
You may try either full retraining (in the spirit of Follow the Regularized Leader) or online iterative updates (Online Gradient Descent).

In your PR, include plots of prediction errors and cumulative loss. 
Compare these errors to those of the best predictions in hindsight (i.e., those of the empirical risk minimizer on all observed data).
